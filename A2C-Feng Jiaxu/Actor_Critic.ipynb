{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrQRwQMZYs9D"
      },
      "source": [
        "# Actor Critic\n",
        "\n",
        "The Actor-Critic algorithm combines Policy Gradient and DQN. It includes two networks: Actor and Critic. The actor learns the policy and decides which action should be taken, and it is updated using Policy Gradient. The critic estimates the value function and informs the actor how good the action was and how it should be adjusted, which is represented by a Deep Q Network.\n",
        "\n",
        "Similar to the intention of the baseline method introduced in Policy Gradient, we want to mitigate the variations caused by random variables in the training process. Therefore, we can try to substitute $G_t$ with its expected value, the state value function $Q_\\pi\\left(s_t, a_t\\right)$. By rewriting it using $Q_\\pi\\left(s_t, a_t\\right)=r_t+V_\\pi\\left(s_{t+1}\\right)$ and representing the baseline as $V_\\pi\\left(s_{t}^n\\right)$, we have the following equation:\n",
        "\n",
        "\\begin{align*}\n",
        "\\nabla_\\theta J(\\theta) \\approx \\mathbb{E}_{\\pi_\\theta}\n",
        "\\left[ \\sum_{t=0}^{T-1} A \\left( s_t, a_t\\right) \\nabla_\\theta \\log \\pi_\\theta(a_t \\ |\\ s_t) \\right]\n",
        "\\end{align*}\n",
        "\n",
        "where the advantage value represents $ A \\left( s_t, a_t\\right) = r_t+V_\\pi\\left(s_{t+1}\\right)-V_\\pi\\left(s_t\\right)$ The advantage function captures how better an action is compared to the others at a given state. In this way, we substitute $G_t$ with a high variance using $r_t$ with a smaller variance to stabilize the model.\n",
        "\n",
        "There is always a trade-off between variance and bias (introduced by the value functions). To balance them, we may explore $A \\left( s_t, a_t\\right) = \\sum_{t^{\\prime}=t+1}^{t+1+n} \\gamma^{t^{\\prime}-t-1} r_{t^{\\prime}} + \\gamma^n V_\\pi\\left(s_{t+n}\\right)-V_\\pi\\left(s_t\\right)\n",
        "$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup & Installation\n",
        "\n",
        "Install all required dependencies, including pytorch and gymnasium which we use for instantiating the learning and testing environment. The code is based on the environment of google colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jbf1NV3Ys2q",
        "outputId": "e41ca753-e41c-4359-af36-ecb301a840ad"
      },
      "outputs": [],
      "source": [
        "!apt update\n",
        "!apt install python3-opengl xvfb -y\n",
        "!sudo apt-get install swig build-essential python2-dev python3-dev\n",
        "!pip install box2d-py pyvirtualdisplay gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qvzH6OuNrvx"
      },
      "outputs": [],
      "source": [
        "from pyvirtualdisplay import Display\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "from tqdm.notebook import tqdm\n",
        "import gymnasium as gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VkcfdTb_89yp"
      },
      "outputs": [],
      "source": [
        "def moving_average(total_rewards):\n",
        "    if len(total_rewards) == 0:\n",
        "        return 0\n",
        "    if len(total_rewards) < 99:\n",
        "        return np.mean(total_rewards)\n",
        "    else:\n",
        "        return np.mean(total_rewards[-100:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = gym.make('LunarLander-v2', render_mode='rgb_array')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# A2C model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tchb3_jiaUC6"
      },
      "outputs": [],
      "source": [
        "class ActorCritic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ActorCritic, self).__init__()\n",
        "        self.affine = nn.Linear(9, 64)\n",
        "\n",
        "        self.action_layer = nn.Linear(64, 4)\n",
        "        self.value_layer = nn.Linear(64, 1)\n",
        "\n",
        "        self.logprobs = []\n",
        "        self.state_values = []\n",
        "        self.rewards = []\n",
        "\n",
        "    def forward(self, state):\n",
        "        state = torch.from_numpy(state).float()\n",
        "        state = F.relu(self.affine(state))\n",
        "\n",
        "        state_value = self.value_layer(state)\n",
        "\n",
        "        action_probs = F.softmax(self.action_layer(state), dim = -1)\n",
        "        action_distribution = Categorical(action_probs)\n",
        "        action = action_distribution.sample()\n",
        "\n",
        "        self.logprobs.append(action_distribution.log_prob(action))\n",
        "        self.state_values.append(state_value)\n",
        "\n",
        "        return action.item()\n",
        "\n",
        "    def calculateLoss(self, gamma=0.99, step=50):\n",
        "\n",
        "        # calculating discounted rewards:\n",
        "        rewards = []\n",
        "        dis_reward = 0\n",
        "        for reward in self.rewards[::-1]:\n",
        "            dis_reward = reward + gamma * dis_reward\n",
        "            rewards.insert(0, dis_reward)\n",
        "\n",
        "        # normalizing the rewards:\n",
        "        rewards = torch.tensor(rewards)\n",
        "        rewards = (rewards - rewards.mean()) / (rewards.std())\n",
        "\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        if step < len(rewards):\n",
        "            for i in range(len(self.rewards)-step):\n",
        "                advantage = (gamma ** step) * self.state_values[i+step].item() + rewards[i] - (gamma ** step) * rewards[i+step] - self.state_values[i].item()\n",
        "                action_loss = -self.logprobs[i] * advantage\n",
        "                value_loss = F.smooth_l1_loss(self.state_values[i], rewards[i])\n",
        "                loss += (action_loss + value_loss)\n",
        "\n",
        "            for i in range(len(self.rewards)-step, len(self.rewards)):\n",
        "                advantage = rewards[i] - self.state_values[i].item()\n",
        "                action_loss = -self.logprobs[i] * advantage\n",
        "                value_loss = F.smooth_l1_loss(self.state_values[i], rewards[i])\n",
        "                loss += (action_loss + value_loss)\n",
        "        else:\n",
        "            for i in range(len(self.rewards)):\n",
        "                advantage = rewards[i] - self.state_values[i].item()\n",
        "                action_loss = -self.logprobs[i] * advantage\n",
        "                value_loss = F.smooth_l1_loss(self.state_values[i], rewards[i])\n",
        "                loss += (action_loss + value_loss)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def clearMemory(self):\n",
        "        del self.logprobs[:]\n",
        "        del self.state_values[:]\n",
        "        del self.rewards[:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2L6DkzgXUWa"
      },
      "source": [
        "# Training\n",
        "\n",
        "Owing to the random seeds, the training result might not be able to replicate the best result. We saved the data for the best training result in 'A2C.pkl' for showing the training process and later testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.02 (0.9, 0.999)\n"
          ]
        }
      ],
      "source": [
        "# Defaults parameters:\n",
        "# gamma = 0.99\n",
        "# lr = 0.02\n",
        "# betas = (0.9, 0.999)\n",
        "# random_seed = 543\n",
        "# step = 50\n",
        "\n",
        "\n",
        "render = False\n",
        "gamma = 0.99\n",
        "lr = 0.02\n",
        "betas = (0.9, 0.999)\n",
        "random_seed = 543\n",
        "step = 50\n",
        "\n",
        "torch.manual_seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "policy = ActorCritic()\n",
        "optimizer = optim.Adam(policy.parameters(), lr=lr, betas=betas)\n",
        "print(lr,betas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CLWBV4VlabY8",
        "outputId": "e42d332d-d31d-4c2c-e165-d8b286013d34"
      },
      "outputs": [],
      "source": [
        "total_rewards = []\n",
        "moving_avg_rewards = []\n",
        "final_rewards = []\n",
        "running_reward = 0\n",
        "i_episode = 0\n",
        "while(moving_average(total_rewards)<220 and i_episode < 1500):\n",
        "    i_episode += 1\n",
        "    state, _ = env.reset(seed=i_episode)\n",
        "    for t in range(1000):\n",
        "        state = np.append(state, t/500)\n",
        "        action = policy(state)\n",
        "        state, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        if t == 999:\n",
        "            reward -= 100\n",
        "        policy.rewards.append(reward)\n",
        "        running_reward += reward\n",
        "        if done:\n",
        "            final_rewards.append(reward)\n",
        "            break\n",
        "\n",
        "    # Updating the policy :\n",
        "    optimizer.zero_grad()\n",
        "    loss = policy.calculateLoss(gamma, step)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    policy.clearMemory()\n",
        "\n",
        "    total_rewards.append(running_reward)\n",
        "    moving_avg_rewards.append(moving_average(total_rewards))\n",
        "    if i_episode % 20 == 0:\n",
        "        print('Episode {}\\tlength: {}\\treward: {}\\tfinal: {}\\taverage reward: {}'.format(i_episode, t, running_reward, reward, moving_avg_rewards[-1]))\n",
        "    running_reward = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('A2C.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "total_rewards = data['total_rewards']\n",
        "moving_avg_rewards = data['moving_average_rewards']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "_3dlTA3B97Vw",
        "outputId": "f0f3bf9d-75a8-4b5f-f9dc-fedf35f12a5c"
      },
      "outputs": [],
      "source": [
        "plt.plot(total_rewards, label='Total Rewards')\n",
        "plt.plot(moving_avg_rewards, color='red', label='Moving Average')\n",
        "plt.legend()\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Reward')\n",
        "plt.ylim(-300, 300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeUPHN6ZXYvi"
      },
      "source": [
        "# Testing\n",
        "\n",
        "After loading the trained model, the expected test result is success rate around 90%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "policy.load_state_dict(torch.load('trained_model'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480,
          "referenced_widgets": [
            "34b44d3475114ef9a37a19dbf0d197df",
            "40df0e7bcca04dceb357028cd7b1551e",
            "9cc2b21ee7f24a828b9e2765da093649",
            "04599dd2759f4bac82de871bbe20443d",
            "4dc2657979244483a1cfc32eac9852c3",
            "3a0c98ce016046c9992e3a13d1bfe840",
            "893f7f7e072e4790ad8ec53f13c70a13",
            "72f17ec29b8649288c38dfd6cf07b4a8",
            "560e179cf34e4798b4469280f77f3a14",
            "dd836ca7cec34fd8b46734cf7d166b59",
            "b4c43055eb3449bcae987f04312cbe14"
          ]
        },
        "id": "ey1c-MfgEThA",
        "outputId": "5552e580-f3cd-47c1-ee71-45b7a6e81232"
      },
      "outputs": [],
      "source": [
        "test_total_rewards = []\n",
        "test_final_rewards = []\n",
        "step_used_list = []\n",
        "test_number = 500\n",
        "prg_bar = tqdm(range(test_number))\n",
        "for i in prg_bar:\n",
        "    actions = []\n",
        "    state = env.reset()[0]\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "    step = 0\n",
        "    while not done :\n",
        "        state = np.append(state, step/500)\n",
        "        step +=1\n",
        "        action = policy(state)\n",
        "        actions.append(action)\n",
        "        state, reward, done, _, _ = env.step(action)\n",
        "        total_reward += reward\n",
        "    test_total_rewards.append(total_reward)\n",
        "    test_final_rewards.append(reward)\n",
        "    step_used_list.append(step)\n",
        "\n",
        "plt.plot([i for i in range(test_number)],test_total_rewards)\n",
        "plt.scatter([i for i in range(test_number)],test_final_rewards,c='r')\n",
        "print(test_final_rewards.count(100)/test_number)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l09QRZnJXhX5"
      },
      "source": [
        "# Visualize Landing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "yXZ_FyZlaidg",
        "outputId": "745adf32-fad7-4164-89be-c0b5982eecae"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "fig = plt.figure()\n",
        "env.reset()\n",
        "img = plt.imshow(env.render())\n",
        "\n",
        "render = True\n",
        "save_gif = False\n",
        "done = False\n",
        "\n",
        "for i_episode in range(1):\n",
        "    ims = []\n",
        "    state,_ = env.reset()\n",
        "    running_reward = 0\n",
        "    step = 0\n",
        "    while not done:\n",
        "        state = np.append(state, step/500)\n",
        "        action = policy(state)\n",
        "        state, reward, done,_ , _ = env.step(action)\n",
        "        running_reward += reward\n",
        "        step += 1\n",
        "        img.set_data(env.render())\n",
        "        im = plt.imshow(env.render(), animated=True)\n",
        "        ims.append([im])\n",
        "        display.display(plt.gcf())\n",
        "        display.clear_output(wait=True)\n",
        "\n",
        "    print('Reward: {}'.format(running_reward))\n",
        "    ani = animation.ArtistAnimation(fig, ims, interval=25, blit=True, repeat_delay=1000)\n",
        "env.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Fy47_KSPwRq",
        "outputId": "e3f3168e-0b18-408a-a1ae-77f233703443"
      },
      "outputs": [],
      "source": [
        "ani.save('A2C.gif', writer='imagemagick')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04599dd2759f4bac82de871bbe20443d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd836ca7cec34fd8b46734cf7d166b59",
            "placeholder": "​",
            "style": "IPY_MODEL_b4c43055eb3449bcae987f04312cbe14",
            "value": " 500/500 [03:06&lt;00:00,  2.76it/s]"
          }
        },
        "34b44d3475114ef9a37a19dbf0d197df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40df0e7bcca04dceb357028cd7b1551e",
              "IPY_MODEL_9cc2b21ee7f24a828b9e2765da093649",
              "IPY_MODEL_04599dd2759f4bac82de871bbe20443d"
            ],
            "layout": "IPY_MODEL_4dc2657979244483a1cfc32eac9852c3"
          }
        },
        "3a0c98ce016046c9992e3a13d1bfe840": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40df0e7bcca04dceb357028cd7b1551e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a0c98ce016046c9992e3a13d1bfe840",
            "placeholder": "​",
            "style": "IPY_MODEL_893f7f7e072e4790ad8ec53f13c70a13",
            "value": "100%"
          }
        },
        "4dc2657979244483a1cfc32eac9852c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "560e179cf34e4798b4469280f77f3a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72f17ec29b8649288c38dfd6cf07b4a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "893f7f7e072e4790ad8ec53f13c70a13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cc2b21ee7f24a828b9e2765da093649": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72f17ec29b8649288c38dfd6cf07b4a8",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_560e179cf34e4798b4469280f77f3a14",
            "value": 500
          }
        },
        "b4c43055eb3449bcae987f04312cbe14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd836ca7cec34fd8b46734cf7d166b59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
